#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆåè§çº æ­£ç³»ç»Ÿ v2.0
author: assistant
date: 2024-12-15

ç‰¹æ€§:
1. è¯­ä¹‰ä¿æŒçš„åè§çº æ­£
2. è¯­å¢ƒæ„ŸçŸ¥çš„çº æ­£ç­–ç•¥
3. ä¸­æ€§åŒ–è¯æ±‡æ˜ å°„  
4. åŠ¨æ€æ¨¡æ¿ç”Ÿæˆ
5. ç»¼åˆçº æ­£æ–¹æ³•èåˆ
6. ä»å¤–éƒ¨JSONæ–‡ä»¶åŠ è½½è§„åˆ™
"""

import re
import json
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleBertBiasDetector:
    """ç®€åŒ–ç‰ˆBERTåè§æ£€æµ‹å™¨"""
    
    def __init__(self, model_path='./coldataset_bias_bert_model'):
        self.model_path = model_path
        self.model = None
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆå ä½ç¬¦ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥åŠ è½½å®é™…çš„BERTæ¨¡å‹
            logger.info("SimpleBertBiasDetector æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"SimpleBertBiasDetector æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def detect_bias(self, text):
        """æ£€æµ‹åè§ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # ç®€å•çš„å…³é”®è¯æ£€æµ‹ä½œä¸ºç¤ºä¾‹
        bias_keywords = {
            'gender': ['ç”·æ€§', 'å¥³æ€§', 'ç”·äºº', 'å¥³äºº'],
            'race': ['é»‘äºº', 'ç™½äºº', 'äºšæ´²äºº'],
            'region': ['æ²³å—äºº', 'ä¸œåŒ—äºº', 'å†œæ‘äºº']
        }
        
        detected_types = []
        for bias_type, keywords in bias_keywords.items():
            if any(kw in text for kw in keywords):
                detected_types.append(bias_type)
        
        if detected_types:
            return {
                'detected_bias_types': detected_types,
                'confidence': 0.8,
                'overall_bias': True
            }
        
        return {
            'detected_bias_types': [],
            'confidence': 0.2,
            'overall_bias': False
        }

@dataclass
class CorrectionResult:
    """çº æ­£ç»“æœæ•°æ®ç±»"""
    original_text: str
    corrected_text: str
    bias_type: str
    correction_method: str
    confidence: float
    explanation: str
    preserved_meaning: bool  # æ˜¯å¦ä¿æŒåŸæ„

class SemanticBiasCorrector:
    """è¯­ä¹‰ä¿æŒçš„åè§çº æ­£å™¨"""
    
    def __init__(self):
        # ä»å¤–éƒ¨JSONæ–‡ä»¶åŠ è½½çº æ­£è§„åˆ™
        self.load_correction_rules()
        logger.info("âœ… SemanticBiasCorrector åˆå§‹åŒ–å®Œæˆ")
        
    def load_correction_rules(self):
        """ä»demo_neutralization_dict.jsonæ–‡ä»¶åŠ è½½çº æ­£è§„åˆ™"""
        try:
            import json
            import os
            
            json_file_path = 'demo_neutralization_dict.json'
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(json_file_path):
                logger.error(f"çº æ­£è§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
                self._load_default_rules()
                return
            
            # ä»JSONæ–‡ä»¶åŠ è½½è§„åˆ™
            with open(json_file_path, 'r', encoding='utf-8') as f:
                rules_data = json.load(f)
            
            # åŠ è½½å„ç§è§„åˆ™ - ä¿®æ­£JSONæ ¼å¼åŒ¹é…
            # JSONæ–‡ä»¶ç›´æ¥åŒ…å«åè§ç±»å‹ä½œä¸ºé¡¶å±‚é”®ï¼Œè€Œä¸æ˜¯åµŒå¥—åœ¨neutralization_dictä¸‹
            self.neutralization_dict = rules_data  # ç›´æ¥ä½¿ç”¨æ•´ä¸ªæ•°æ®ä½œä¸ºneutralization_dict
            self.semantic_corrections = rules_data.get('semantic_corrections', {})
            self.context_preserving_templates = rules_data.get('context_preserving_templates', {})
            
            logger.info(f"âœ… æˆåŠŸä» {json_file_path} åŠ è½½çº æ­£è§„åˆ™")
            logger.info(f"   ğŸ“ åŠ è½½äº† {len(self.neutralization_dict)} ä¸ªåè§ç±»å‹çš„ä¸­æ€§åŒ–è¯å…¸")
            logger.info(f"   ğŸ” åŠ è½½äº† {len(self.semantic_corrections)} ä¸ªåè§ç±»å‹çš„è¯­ä¹‰è§„åˆ™")
            
        except Exception as e:
            logger.error(f"âŒ ä»JSONæ–‡ä»¶åŠ è½½çº æ­£è§„åˆ™å¤±è´¥: {e}")
            logger.info("ğŸ”„ ä½¿ç”¨é»˜è®¤å†…ç½®è§„åˆ™")
            self._load_default_rules()
    
    def _load_default_rules(self):
        """åŠ è½½é»˜è®¤çš„å†…ç½®çº æ­£è§„åˆ™ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        self.semantic_corrections = {
            'gender': {
                'comparison_patterns': [
                    {
                        'pattern': r'ç”·æ€§.*?æ¯”.*?å¥³æ€§.*?æ›´',
                        'template': 'åœ¨è¯¥é¢†åŸŸï¼Œä¸ªä½“å·®å¼‚æ¯”æ€§åˆ«å·®å¼‚æ›´é‡è¦',
                        'context_extract': r'(å·¥ä½œ|èƒ½åŠ›|è¡¨ç°)'
                    }
                ]
            }
        }
        
        # é»˜è®¤çš„ç®€åŒ–è§„åˆ™ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        self.neutralization_dict = {
            'gender': {
                "ç”·æ€§æ¯”å¥³æ€§æ›´": "åœ¨è¯¥é¢†åŸŸï¼Œä¸ªä½“å·®å¼‚æ¯”æ€§åˆ«å·®å¼‚æ›´",
                "å¥³æ€§æ¯”ç”·æ€§æ›´": "åœ¨è¯¥é¢†åŸŸï¼Œä¸ªä½“å·®å¼‚æ¯”æ€§åˆ«å·®å¼‚æ›´",
                "æ ¹æ®æ•°æ®æ˜¾ç¤ºï¼Œåœ¨æŸäº›å·¥ä½œå’Œè¡Œä¸šä¸­ï¼Œç”·æ€§ç¡®å®è¡¨ç°å‡ºäº†æ›´é«˜çš„å·¥ä½œèƒ½åŠ›å’Œæˆå°±": "å·¥ä½œèƒ½åŠ›å’Œæˆå°±çš„è¯„ä¼°åº”è¯¥åŸºäºä¸ªäººçš„å…·ä½“è¡¨ç°ï¼Œè€Œä¸æ˜¯æ€§åˆ«ã€‚åœ¨ä»»ä½•è¡Œä¸šä¸­ï¼Œä¸ªä½“å·®å¼‚éƒ½è¿œå¤§äºæ€§åˆ«å·®å¼‚"
            },
            'race': {
                "é»‘äººæ™ºåŠ›": "ä¸ªä½“æ™ºåŠ›",
                "ç™½äººæ›´ä¼˜ç§€": "ä¸åŒä¸ªä½“å„æœ‰ä¼˜åŠ¿"
            },
            'region': {
                "æ²³å—äººéƒ½æ˜¯": "æŸäº›ä¸ªä½“å¯èƒ½",
                "å†œæ‘äººç´ è´¨ä½": "æ•™è‚²èµ„æºä¸è¶³åœ°åŒºçš„äººä»¬"
            }
        }
        
        # è¯­å¢ƒä¿æŒæ¨¡æ¿
        self.context_preserving_templates = {
            'work_ability': 'è¯„ä»·å·¥ä½œèƒ½åŠ›æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥æ›´å…¨é¢åœ°è€ƒè™‘å„ç§å› ç´ ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾æ®{bias_factor}',
            'general': 'ä¸ªä½“å·®å¼‚æ¯”ç¾¤ä½“å·®å¼‚æ›´ä¸ºé‡è¦ï¼Œä¸åº”åŸºäº{bias_factor}è¿›è¡Œæ¦‚æ‹¬'
        }
    
    def extract_context(self, text: str, pattern_info: Dict) -> str:
        """æå–è¯­å¢ƒä¿¡æ¯"""
        if 'context_extract' in pattern_info:
            context_match = re.search(pattern_info['context_extract'], text)
            if context_match:
                return context_match.group(1)
        return "ç›¸å…³é¢†åŸŸ"
    
    def extract_skill(self, text: str, pattern_info: Dict) -> str:
        """æå–æŠ€èƒ½ä¿¡æ¯"""
        if 'skill_extract' in pattern_info:
            skill_match = re.search(pattern_info['skill_extract'], text)
            if skill_match:
                return skill_match.group(1)
        return "ç‰¹å®š"
    
    def neutralize_with_dict(self, text: str, bias_type: str) -> Tuple[str, bool]:
        """ä½¿ç”¨è¯æ±‡æ˜ å°„è¿›è¡Œä¸­æ€§åŒ–"""
        if bias_type not in self.neutralization_dict:
            return text, False
        
        neutralized_text = text
        changed = False
        
        for biased_phrase, neutral_phrase in self.neutralization_dict[bias_type].items():
            if biased_phrase in text:
                neutralized_text = neutralized_text.replace(biased_phrase, neutral_phrase)
                changed = True
        
        return neutralized_text, changed
    
    def correct_with_semantic_preservation(self, text: str, bias_types: List[str]) -> Optional[CorrectionResult]:
        """è¯­ä¹‰ä¿æŒçš„åè§çº æ­£"""
        logger.info(f"å¼€å§‹è¯­ä¹‰ä¿æŒçº æ­£: {bias_types}")
        
        # å…ˆå°è¯•ç²¾ç¡®åŒ¹é…çº æ­£
        for bias_type in bias_types:
            if bias_type in self.neutralization_dict:
                neutralized_text, changed = self.neutralize_with_dict(text, bias_type)
                if changed:
                    return CorrectionResult(
                        original_text=text,
                        corrected_text=neutralized_text,
                        bias_type=bias_type,
                        correction_method="è¯æ±‡æ˜ å°„ä¸­æ€§åŒ–",
                        confidence=0.9,
                        explanation=f"é€šè¿‡{bias_type}åè§è¯æ±‡æ˜ å°„è¿›è¡Œä¸­æ€§åŒ–çº æ­£",
                        preserved_meaning=True
                    )
        
        # å†å°è¯•è¯­ä¹‰è§„åˆ™çº æ­£
        for bias_type in bias_types:
            if bias_type not in self.semantic_corrections:
                continue
            
            corrections = self.semantic_corrections[bias_type]
            
            # 1. å°è¯•ç²¾ç¡®æ¨¡å¼åŒ¹é…
            for pattern_type, patterns in corrections.items():
                if not isinstance(patterns, list):
                    continue
                    
                for pattern_info in patterns:
                    pattern = pattern_info['pattern']
                    template = pattern_info['template']
                    
                    if re.search(pattern, text, re.IGNORECASE):
                        # æå–è¯­å¢ƒä¿¡æ¯
                        context = self.extract_context(text, pattern_info)
                        skill = self.extract_skill(text, pattern_info)
                        
                        # ç”Ÿæˆä¿æŒè¯­ä¹‰çš„çº æ­£
                        if '{context}' in template:
                            corrected_text = template.format(context=context)
                        elif '{skill}' in template:
                            corrected_text = template.format(skill=skill)
                        else:
                            corrected_text = template
                        
                        return CorrectionResult(
                            original_text=text,
                            corrected_text=corrected_text,
                            bias_type=bias_type,
                            correction_method="è¯­ä¹‰ä¿æŒçº æ­£",
                            confidence=0.85,
                            explanation=f"ä½¿ç”¨{pattern_type}æ¨¡å¼è¿›è¡Œè¯­ä¹‰ä¿æŒçº æ­£",
                            preserved_meaning=True
                        )
            
        return None
    
    def correct_with_neutralization(self, text: str, bias_types: List[str]) -> Optional[CorrectionResult]:
        """ä½¿ç”¨ä¸­æ€§åŒ–è¯å…¸è¿›è¡Œçº æ­£"""
        logger.info(f"å¼€å§‹ä¸­æ€§åŒ–è¯å…¸çº æ­£: {bias_types}")
        
        for bias_type in bias_types:
            corrected_text, changed = self.neutralize_with_dict(text, bias_type)
            
            if changed:
                return CorrectionResult(
                    original_text=text,
                    corrected_text=corrected_text,
                    bias_type=bias_type,
                    correction_method="è¯æ±‡æ˜ å°„ä¸­æ€§åŒ–",
                    confidence=0.8,
                    explanation="ä½¿ç”¨ä¸­æ€§åŒ–è¯æ±‡æ›¿æ¢åè§è¡¨è¾¾",
                    preserved_meaning=True
                )
        
        return None

class ContextAwareBiasCorrector:
    """è¯­å¢ƒæ„ŸçŸ¥çš„åè§çº æ­£å™¨"""
    
    def __init__(self):
        # è¯­å¢ƒåˆ†ç±»å™¨
        self.context_classifiers = {
            'work_evaluation': ['å·¥ä½œ', 'èƒ½åŠ›', 'è¡¨ç°', 'æˆå°±', 'ä¸šç»©', 'èŒåœº', 'ä¸“ä¸š'],
            'academic_discussion': ['å­¦ä¹ ', 'å­¦æœ¯', 'ç ”ç©¶', 'æ•™è‚²', 'çŸ¥è¯†', 'æ™ºåŠ›', 'æˆç»©'],
            'social_interaction': ['ç¤¾äº¤', 'æ²Ÿé€š', 'äº¤æµ', 'åˆä½œ', 'å›¢é˜Ÿ', 'äººé™…'],
            'cultural_comparison': ['æ–‡åŒ–', 'ä¼ ç»Ÿ', 'ä¹ ä¿—', 'ä»·å€¼è§‚', 'ç¤¾ä¼š', 'æ°‘æ—'],
            'personal_traits': ['æ€§æ ¼', 'ç‰¹è´¨', 'å“æ ¼', 'ç´ è´¨', 'ä¿®å…»', 'å“å¾·']
        }
    
    def classify_context(self, text: str) -> str:
        """åˆ†ç±»è¯­å¢ƒ"""
        for context, keywords in self.context_classifiers.items():
            if any(keyword in text for keyword in keywords):
                return context
        return 'general'
    
    def generate_context_aware_correction(self, text: str, bias_type: str, context: str) -> str:
        """ç”Ÿæˆè¯­å¢ƒæ„ŸçŸ¥çš„çº æ­£"""
        context_templates = {
            'work_evaluation': {
                'gender': 'è¯„ä»·å·¥ä½œèƒ½åŠ›æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥æ›´å…¨é¢åœ°è€ƒè™‘å„ç§å› ç´ ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾æ®æ€§åˆ«',
                'race': 'å·¥ä½œè¡¨ç°çš„è¯„ä»·åº”è¯¥åŸºäºä¸ªäººèƒ½åŠ›å’Œè´¡çŒ®ï¼Œè€Œéç§æ—èƒŒæ™¯',
                'region': 'èŒåœºè¯„ä»·åº”è¯¥å…³æ³¨ä¸ªäººä¸“ä¸šèƒ½åŠ›ï¼Œè€Œéåœ°åŸŸå‡ºèº«'
            },
            'academic_discussion': {
                'gender': 'å­¦æœ¯èƒ½åŠ›çš„å·®å¼‚ä¸»è¦æ¥è‡ªä¸ªäººå…´è¶£ã€åŠªåŠ›ç¨‹åº¦å’Œæ•™è‚²æœºä¼šï¼Œè€Œéæ€§åˆ«',
                'race': 'å­¦æœ¯æˆå°±ä½“ç°ä¸ªäººåŠªåŠ›å’Œå¤©èµ‹ï¼Œä¸ç§æ—èƒŒæ™¯æ— å…³',
                'region': 'æ•™è‚²æˆæœä¸»è¦å–å†³äºä¸ªäººåŠªåŠ›å’Œæ•™è‚²èµ„æºï¼Œè€Œéåœ°åŸŸå› ç´ '
            },
            'general': {
                'gender': 'ä¸ªä½“å·®å¼‚æ¯”æ€§åˆ«å·®å¼‚æ›´ä¸ºé‡è¦',
                'race': 'ä¸ªäººç‰¹è´¨ä¸ç§æ—èƒŒæ™¯æ— å…³',
                'region': 'ä¸ªäººå“è´¨ä¸åœ°åŸŸå‡ºèº«æ— å…³'
            }
        }
        
        if context in context_templates and bias_type in context_templates[context]:
            return context_templates[context][bias_type]
        elif bias_type in context_templates['general']:
            return context_templates['general'][bias_type]
        else:
            return f'åœ¨è¯„ä»·ä¸ªäºº{bias_type}ç›¸å…³ç‰¹è´¨æ—¶ï¼Œåº”è¯¥å…³æ³¨ä¸ªä½“å·®å¼‚è€Œéç¾¤ä½“åˆ»æ¿å°è±¡'

class EnhancedBiasCorrectionSystem:
    """å¢å¼ºç‰ˆåè§çº æ­£ç³»ç»Ÿ"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.bias_detector = SimpleBertBiasDetector()
        self.semantic_corrector = SemanticBiasCorrector()
        self.context_corrector = ContextAwareBiasCorrector()
        
        logger.info("âœ… å¢å¼ºç‰ˆåè§çº æ­£ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logger.info("   ğŸ” åè§æ£€æµ‹å™¨: SimpleBertBiasDetector")
        logger.info("   ğŸ› ï¸ è¯­ä¹‰çº æ­£å™¨: SemanticBiasCorrector")
        logger.info("   ğŸ“ è¯­å¢ƒçº æ­£å™¨: ContextAwareBiasCorrector")
    
    def detect_bias(self, text: str) -> Tuple[bool, List[str], float, str]:
        """æ£€æµ‹åè§"""
        try:
            result = self.bias_detector.detect_bias(text)
        
            has_bias = result.get('overall_bias', False)
            bias_types = result.get('detected_bias_types', [])
            confidence = result.get('confidence', 0.0)
            
            summary = f"æ£€æµ‹åˆ°{len(bias_types)}ç§åè§ç±»å‹: {', '.join(bias_types)}" if has_bias else "æœªæ£€æµ‹åˆ°åè§"
            
            return has_bias, bias_types, confidence, summary
            
        except Exception as e:
            logger.error(f"åè§æ£€æµ‹å‡ºé”™: {e}")
            return False, [], 0.0, "æ£€æµ‹å‡ºé”™"
    
    def correct_bias_enhanced(self, text: str) -> Optional[CorrectionResult]:
        """å¢å¼ºç‰ˆåè§çº æ­£ä¸»æ–¹æ³•"""
        logger.info(f"å¼€å§‹å¢å¼ºç‰ˆåè§çº æ­£: {text[:50]}...")
        
        # 1. æ£€æµ‹åè§
        has_bias, bias_types, confidence, summary = self.detect_bias(text)
        
        if not has_bias:
            logger.info("æœªæ£€æµ‹åˆ°åè§ï¼Œæ— éœ€çº æ­£")
            return None
        
        logger.info(f"æ£€æµ‹åˆ°åè§ç±»å‹: {bias_types}")
        
        # 2. å°è¯•è¯­ä¹‰ä¿æŒçº æ­£
        semantic_result = self.semantic_corrector.correct_with_semantic_preservation(text, bias_types)
        if semantic_result:
            logger.info("è¯­ä¹‰ä¿æŒçº æ­£æˆåŠŸ")
            return semantic_result
        
        # 3. å°è¯•è¯æ±‡æ˜ å°„ä¸­æ€§åŒ–
        neutralization_result = self.semantic_corrector.correct_with_neutralization(text, bias_types)
        if neutralization_result:
            logger.info("è¯æ±‡æ˜ å°„ä¸­æ€§åŒ–æˆåŠŸ")
            return neutralization_result
        
        # 4. ä½¿ç”¨è¯­å¢ƒæ„ŸçŸ¥çº æ­£
        context = self.context_corrector.classify_context(text)
        primary_bias_type = bias_types[0] if bias_types else 'general'
        corrected_text = self.context_corrector.generate_context_aware_correction(text, primary_bias_type, context)
        
        logger.info("ä½¿ç”¨è¯­å¢ƒæ„ŸçŸ¥çº æ­£")
        return CorrectionResult(
            original_text=text,
            corrected_text=corrected_text,
            bias_type=primary_bias_type,
            correction_method="è¯­å¢ƒæ„ŸçŸ¥çº æ­£",
            confidence=0.7,
            explanation=f"åŸºäº{context}è¯­å¢ƒè¿›è¡Œçº æ­£",
            preserved_meaning=True
        )
    
    def interactive_correction_enhanced(self):
        """å¢å¼ºç‰ˆäº¤äº’å¼çº æ­£"""
        print("\nğŸš€ å¢å¼ºç‰ˆåè§çº æ­£ç³»ç»Ÿ v2.0")
        print("=" * 50)
        print("è¾“å…¥æ–‡æœ¬è¿›è¡Œåè§æ£€æµ‹å’Œçº æ­£ï¼Œè¾“å…¥ 'quit' é€€å‡º")
        print("ç‰¹æ€§ï¼šè¯­ä¹‰ä¿æŒã€è¯­å¢ƒæ„ŸçŸ¥ã€ç»¼åˆçº æ­£ç­–ç•¥")
        print("=" * 50)
        
        while True:
            try:
                text = input("\nè¯·è¾“å…¥æ–‡æœ¬: ").strip()
                if text.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if not text:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ–‡æœ¬")
                    continue
                
                print(f"\nğŸ“ åŸæ–‡: {text}")
                print("-" * 30)
                
                # æ£€æµ‹å’Œçº æ­£
                result = self.correct_bias_enhanced(text)
                
                if result:
                    print(f"âœ… æ£€æµ‹åˆ°åè§: {result.bias_type}")
                    print(f"ğŸ”§ çº æ­£æ–¹æ³•: {result.correction_method}")
                    print(f"âœ¨ çº æ­£ç»“æœ: {result.corrected_text}")
                else:
                    print("âœ… æ— åè§æˆ–æ— éœ€çº æ­£")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    system = EnhancedBiasCorrectionSystem()
    
    # æµ‹è¯•æ¡ˆä¾‹
    test_cases = [
        "æ ¹æ®æ•°æ®æ˜¾ç¤ºï¼Œåœ¨æŸäº›å·¥ä½œå’Œè¡Œä¸šä¸­ï¼Œç”·æ€§ç¡®å®è¡¨ç°å‡ºäº†æ›´é«˜çš„å·¥ä½œèƒ½åŠ›å’Œæˆå°±ã€‚",
        "æ²³å—äººéƒ½æ˜¯éª—å­",
        "é»‘äººæ™ºåŠ›æ™®éè¾ƒä½",
        "è¿™ä¸ªå·¥ä½œé€‚åˆç”·æ€§æ¥åš"
    ]
    
    print("\nğŸ§ª æµ‹è¯•å¢å¼ºç‰ˆåè§çº æ­£ç³»ç»Ÿ")
    print("=" * 50)
    
    for i, test_text in enumerate(test_cases, 1):
        print(f"\næµ‹è¯• {i}: {test_text}")
        print("-" * 30)
        
        result = system.correct_bias_enhanced(test_text)
        if result:
            print(f"âœ… åè§ç±»å‹: {result.bias_type}")
            print(f"ğŸ”§ çº æ­£æ–¹æ³•: {result.correction_method}")
            print(f"âœ¨ çº æ­£ç»“æœ: {result.corrected_text}")
        else:
            print("âœ… æ— åè§æˆ–æ— éœ€çº æ­£")
    
    # å¯åŠ¨äº¤äº’æ¨¡å¼
    print(f"\nå¯åŠ¨äº¤äº’æ¨¡å¼...")
    system.interactive_correction_enhanced()

if __name__ == "__main__":
    main() 