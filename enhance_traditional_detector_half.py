import pandas as pd
import jieba
import pickle
from collections import Counter
import re
import os
import numpy as np
import json
from sklearn.model_selection import train_test_split
from traditional_bias_detector import SVMBiasClassifier, SensitiveWordMatcher, SentimentAnalyzer

# --- é…ç½® ---
DATA_DIR = 'COLDataset-main/COLDataset'
TRAIN_FILE = os.path.join(DATA_DIR, 'train.csv')
TEST_FILE = os.path.join(DATA_DIR, 'test.csv')

OUTPUT_DIR = 'coldataset_bias_traditional_model_half'
OUTPUT_SVM_MODEL = os.path.join(OUTPUT_DIR, 'svm_model.pkl')
OUTPUT_SENSITIVE_WORDS = os.path.join(OUTPUT_DIR, 'new_sensitive_words.json')
OUTPUT_SENTIMENT_WORDS = os.path.join(OUTPUT_DIR, 'new_sentiment_words.json')

# æ•°æ®é‡‡æ ·é…ç½®
SAMPLE_RATIO = 0.5  # ä½¿ç”¨ä¸€åŠçš„æ•°æ®
MIN_TEXT_LENGTH = 5   # æœ€å°æ–‡æœ¬é•¿åº¦
MAX_TEXT_LENGTH = 300 # æ–‡æœ¬é•¿åº¦é™åˆ¶

def load_and_sample_data():
    """
    åŠ è½½å¹¶é‡‡æ ·ä¸€åŠçš„COLDatasetæ•°æ®
    """
    print("ğŸš€ åŠ è½½å¹¶é‡‡æ ·COLDatasetæ•°æ®é›†...")
    
    try:
        # åŠ è½½æ•°æ®
        train_df = pd.read_csv(TRAIN_FILE)
        test_df = pd.read_csv(TEST_FILE)
        
        print(f"  - è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
        print(f"  - æµ‹è¯•é›†: {len(test_df)} æ ·æœ¬")
        
        # æ•°æ®æ¸…æ´—å’Œé€‰æ‹©
        train_df = train_df[['TEXT', 'label']].dropna()
        if 'topic' in test_df.columns:
            test_df = test_df[['TEXT', 'label', 'topic']].dropna()
        else:
            test_df = test_df[['TEXT', 'label']].dropna()
        
        # åˆå¹¶æ•°æ®é›†
        full_df = pd.concat([train_df, test_df], ignore_index=True)
        print(f"  - åˆå¹¶åæ€»æ•°æ®: {len(full_df)} æ ·æœ¬")
        
        # åŸºæœ¬è´¨é‡è¿‡æ»¤ï¼šæ–‡æœ¬é•¿åº¦
        full_df['text_length'] = full_df['TEXT'].astype(str).str.len()
        filtered_df = full_df[
            (full_df['text_length'] >= MIN_TEXT_LENGTH) & 
            (full_df['text_length'] <= MAX_TEXT_LENGTH)
        ]
        
        print(f"  - è´¨é‡è¿‡æ»¤å: {len(filtered_df)} æ ·æœ¬")
        
        # å¹³è¡¡é‡‡æ ·ï¼šç¡®ä¿æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ä¿æŒåŸæœ‰å¹³è¡¡
        safe_samples = filtered_df[filtered_df['label'] == 0]
        offensive_samples = filtered_df[filtered_df['label'] == 1]
        
        # è®¡ç®—é‡‡æ ·æ•°é‡
        target_safe = int(len(safe_samples) * SAMPLE_RATIO)
        target_offensive = int(len(offensive_samples) * SAMPLE_RATIO)
        
        print(f"  - é‡‡æ ·æ¯”ä¾‹: {SAMPLE_RATIO*100:.0f}%")
        print(f"  - Safeæ ·æœ¬: {len(safe_samples)} -> {target_safe}")
        print(f"  - Offensiveæ ·æœ¬: {len(offensive_samples)} -> {target_offensive}")
        
        # éšæœºé‡‡æ ·
        sampled_safe = safe_samples.sample(n=target_safe, random_state=42)
        sampled_offensive = offensive_samples.sample(n=target_offensive, random_state=42)
        
        # åˆå¹¶é‡‡æ ·ç»“æœ
        sampled_df = pd.concat([sampled_safe, sampled_offensive], ignore_index=True)
        
        # å¦‚æœtestæ•°æ®æœ‰topicä¿¡æ¯ï¼Œå°½é‡ä¿ç•™
        if 'topic' in test_df.columns:
            # ä¸ºsampled_dfæ·»åŠ topicä¿¡æ¯ï¼ˆå¦‚æœåŸå§‹æ•°æ®æœ‰çš„è¯ï¼‰
            topic_map = {}
            if 'topic' in full_df.columns:
                for idx, row in full_df.iterrows():
                    if pd.notna(row.get('topic')):
                        topic_map[idx] = row['topic']
                
                # ä¸ºé‡‡æ ·åçš„æ•°æ®æ·»åŠ topicä¿¡æ¯
                sampled_df['topic'] = sampled_df.index.map(lambda x: topic_map.get(x, None))
        
        print(f"  - æœ€ç»ˆé‡‡æ ·ç»“æœ: {len(sampled_df)} æ ·æœ¬")
        print(f"  - Safe: {sum(sampled_df['label'] == 0)}")
        print(f"  - Offensive: {sum(sampled_df['label'] == 1)}")
        
        return sampled_df
        
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿ '{DATA_DIR}' ç›®å½•å­˜åœ¨ä¸”åŒ…å«æ‰€éœ€æ–‡ä»¶ã€‚")
        return None
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

# --- 1. ä½¿ç”¨ä¸€åŠæ•°æ®è®­ç»ƒå¹¶ä¿å­˜SVMæ¨¡å‹ ---
def train_and_save_svm_half(df):
    """ä½¿ç”¨ä¸€åŠCOLDatasetè®­ç»ƒå¹¶ä¿å­˜SVMåˆ†ç±»å™¨"""
    print("\nğŸš€ ä½¿ç”¨ä¸€åŠæ•°æ®è®­ç»ƒSVMåˆ†ç±»å™¨...")
    
    try:
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        texts = df['TEXT'].astype(str).tolist()
        labels = df['label'].astype(int).tolist()
        
        print(f"  - è®­ç»ƒæ ·æœ¬æ•°: {len(texts)}")
        print(f"  - æ­£æ ·æœ¬(åè§): {sum(labels)}")
        print(f"  - è´Ÿæ ·æœ¬(æ­£å¸¸): {len(labels) - sum(labels)}")

        # è®­ç»ƒSVM
        svm_classifier = SVMBiasClassifier()
        print("  - æ­£åœ¨è®­ç»ƒSVMæ¨¡å‹...")
        svm_classifier.train(texts, labels)
        print("  - SVMæ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        with open(OUTPUT_SVM_MODEL, 'wb') as f:
            pickle.dump(svm_classifier, f)
        
        model_size = os.path.getsize(OUTPUT_SVM_MODEL) / (1024 * 1024)  # MB
        print(f"âœ… SVMæ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ°: {OUTPUT_SVM_MODEL}")
        print(f"  - æ¨¡å‹å¤§å°: {model_size:.1f} MB")

    except Exception as e:
        print(f"âŒ è®­ç»ƒSVMæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

# --- 2. ä»ä¸€åŠæ•°æ®æå–å¹¶ä¿å­˜æ•æ„Ÿè¯è¯å…¸ ---
def extract_and_save_sensitive_words_half(df):
    """ä»ä¸€åŠCOLDatasetä¸­æå–å¹¶ä¿å­˜æ•æ„Ÿè¯"""
    print("\nğŸš€ ä»ä¸€åŠæ•°æ®æå–æ•æ„Ÿè¯è¯å…¸...")
    
    try:
        # å¦‚æœæœ‰topicä¿¡æ¯ï¼Œä½¿ç”¨topicåˆ†ç±»ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤åˆ†ç±»
        if 'topic' in df.columns:
            # ç­›é€‰å‡ºæœ‰åè§ä¸”æœ‰ä¸»é¢˜åˆ†ç±»çš„æ–‡æœ¬
            offensive_df = df[(df['label'] == 1) & (df['topic'].notna())]
            print(f"  - æ‰¾åˆ° {len(offensive_df)} æ¡å¸¦ä¸»é¢˜çš„åè§æ ·æœ¬ã€‚")
        else:
            # æ²¡æœ‰topicä¿¡æ¯ï¼Œä½¿ç”¨æ‰€æœ‰åè§æ ·æœ¬å¹¶æ‰‹åŠ¨åˆ†ç±»
            offensive_df = df[df['label'] == 1]
            print(f"  - æ‰¾åˆ° {len(offensive_df)} æ¡åè§æ ·æœ¬ï¼Œå°†è¿›è¡Œæ‰‹åŠ¨åˆ†ç±»ã€‚")

        # æ‰©å±•çš„åœç”¨è¯åˆ—è¡¨
        stopwords = set([
            'çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'éƒ½', 'ä¹Ÿ', 'è¿˜', 'å°±', 
            'è¿™ä¸ª', 'ä¸€ä¸ª', 'ä»€ä¹ˆ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'ä½†æ˜¯', 'æ‰€ä»¥', 'ä¸æ˜¯', 
            'æœ‰', 'æ²¡æœ‰', 'å¯ä»¥', 'ä¼š', 'è¦', 'å¾ˆ', 'æ›´', 'æœ€', 'åœ¨', 'å’Œ', 'æˆ–è€…',
            'å› ä¸º', 'å¦‚æœ', 'é‚£ä¹ˆ', 'è¿™æ ·', 'é‚£æ ·', 'åº”è¯¥', 'å¯èƒ½', 'å·²ç»', 'ç„¶å',
            'ç°åœ¨', 'ä»¥å', 'ä¹‹å‰', 'ä¸€ç›´', 'æ€»æ˜¯', 'ä»æ¥', 'æ°¸è¿œ', 'ç»å¯¹'
        ])
        
        new_sensitive_words = {}
        
        if 'topic' in df.columns and not df['topic'].isna().all():
            # æŒ‰ä¸»é¢˜åˆ†ç»„æå–æ•æ„Ÿè¯
            topic_mapping = {
                'gender': 'gender',
                'race': 'race', 
                'region': 'region'
            }
            
            for topic, group in offensive_df.groupby('topic'):
                print(f"  - æ­£åœ¨å¤„ç†ä¸»é¢˜: {topic} ({len(group)} æ ·æœ¬)")
                text_corpus = ' '.join(group['TEXT'].astype(str))
                
                # ä½¿ç”¨jiebaåˆ†è¯
                words = [word for word in jieba.lcut(text_corpus) 
                        if len(word) > 1 and word not in stopwords and not word.isdigit()]
                
                # ç»Ÿè®¡è¯é¢‘
                word_counts = Counter(words)
                
                # æå–é«˜é¢‘è¯ï¼Œæ ¹æ®æ ·æœ¬æ•°é‡åŠ¨æ€è°ƒæ•´
                min_freq = max(2, len(group) // 200)  # åŠ¨æ€é˜ˆå€¼ï¼Œæ¯”å®Œæ•´ç‰ˆæ›´å®½æ¾
                top_words = [word for word, count in word_counts.most_common(80) 
                           if count >= min_freq]
                
                # æ˜ å°„åˆ°æ ‡å‡†åˆ†ç±»
                standard_topic = topic_mapping.get(topic, topic)
                new_sensitive_words[standard_topic] = top_words
                
                print(f"    - æå–å…³é”®è¯ ({len(top_words)}ä¸ªï¼Œæœ€å°é¢‘æ¬¡â‰¥{min_freq})")
                print(f"    - ç¤ºä¾‹è¯æ±‡: {', '.join(top_words[:10])}...")
        else:
            # æ²¡æœ‰topicä¿¡æ¯ï¼Œæ ¹æ®å…³é”®è¯æ¨¡å¼æ‰‹åŠ¨åˆ†ç±»
            print("  - æ²¡æœ‰ä¸»é¢˜ä¿¡æ¯ï¼Œä½¿ç”¨å…³é”®è¯æ¨¡å¼è¿›è¡Œè‡ªåŠ¨åˆ†ç±»...")
            
            # åˆ†ç±»å…³é”®è¯æ¨¡å¼
            gender_patterns = ['å¥³', 'ç”·', 'æ€§åˆ«', 'å¦‡å¥³', 'ç”·äºº', 'å¥³äºº', 'å§‘å¨˜', 'å°ä¼™']
            race_patterns = ['é»‘äºº', 'ç™½äºº', 'ç§æ—', 'æ°‘æ—', 'ä¸­å›½', 'ç¾å›½', 'æ—¥æœ¬', 'éŸ©å›½', 'å°åº¦']
            region_patterns = ['åœ°åŒº', 'åœ°æ–¹', 'åŸå¸‚', 'å†œæ‘', 'ä¸œåŒ—', 'å—æ–¹', 'åŒ—æ–¹', 'ä¸Šæµ·', 'åŒ—äº¬']
            
            all_text = ' '.join(offensive_df['TEXT'].astype(str))
            words = [word for word in jieba.lcut(all_text) 
                    if len(word) > 1 and word not in stopwords and not word.isdigit()]
            word_counts = Counter(words)
            
            # æŒ‰æ¨¡å¼åˆ†ç±»
            for category, patterns in [('gender', gender_patterns), 
                                     ('race', race_patterns), 
                                     ('region', region_patterns)]:
                
                category_words = []
                for word, count in word_counts.most_common(500):
                    if any(pattern in word for pattern in patterns) or count >= 8:
                        category_words.append(word)
                        if len(category_words) >= 60:  # æ¯ç±»æœ€å¤š60ä¸ªè¯
                            break
                
                new_sensitive_words[category] = category_words
                print(f"    - {category}: {len(category_words)}ä¸ªè¯æ±‡")

        # ä¿å­˜ä¸ºJSON
        with open(OUTPUT_SENSITIVE_WORDS, 'w', encoding='utf-8') as f:
            json.dump(new_sensitive_words, f, ensure_ascii=False, indent=4)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_words = sum(len(words) for words in new_sensitive_words.values())
        print(f"âœ… æ•æ„Ÿè¯è¯å…¸å·²ä¿å­˜åˆ°: {OUTPUT_SENSITIVE_WORDS}")
        print(f"  - æ€»è¯æ±‡æ•°: {total_words}")
        for category, words in new_sensitive_words.items():
            print(f"  - {category}: {len(words)}ä¸ª")

    except Exception as e:
        print(f"âŒ æå–æ•æ„Ÿè¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

# --- 3. ä»ä¸€åŠæ•°æ®æå–å¹¶ä¿å­˜æƒ…æ„Ÿè¯è¯å…¸ ---
def extract_and_save_sentiment_words_half(df):
    """ä»ä¸€åŠCOLDatasetä¸­æå–å¹¶ä¿å­˜æƒ…æ„Ÿè¯å…¸"""
    print("\nğŸš€ ä»ä¸€åŠæ•°æ®æå–æƒ…æ„Ÿè¯å…¸...")
    
    try:
        # åˆ†åˆ«å¤„ç†æ­£é¢å’Œè´Ÿé¢æ ·æœ¬
        safe_texts = df[df['label'] == 0]['TEXT'].astype(str)
        offensive_texts = df[df['label'] == 1]['TEXT'].astype(str)
        
        print(f"  - æ­£å¸¸æ ·æœ¬: {len(safe_texts)}æ¡")
        print(f"  - åè§æ ·æœ¬: {len(offensive_texts)}æ¡")
        
        # åœç”¨è¯
        stopwords = set([
            'çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'éƒ½', 'ä¹Ÿ', 'è¿˜', 'å°±',
            'è¿™ä¸ª', 'ä¸€ä¸ª', 'ä»€ä¹ˆ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'ä½†æ˜¯', 'æ‰€ä»¥', 'ä¸æ˜¯',
            'æœ‰', 'æ²¡æœ‰', 'å¯ä»¥', 'ä¼š', 'è¦', 'å¾ˆ', 'æ›´', 'æœ€'
        ])

        # ä»æ­£å¸¸æ–‡æœ¬ä¸­æå–æ­£é¢è¯æ±‡
        print("  - æ­£åœ¨åˆ†ææ­£å¸¸æ–‡æœ¬...")
        safe_corpus = ' '.join(safe_texts)
        safe_words = [word for word in jieba.lcut(safe_corpus) 
                     if len(word) > 1 and word not in stopwords and not word.isdigit()]
        safe_word_counts = Counter(safe_words)

        # ä»åè§æ–‡æœ¬ä¸­æå–è´Ÿé¢è¯æ±‡
        print("  - æ­£åœ¨åˆ†æåè§æ–‡æœ¬...")
        offensive_corpus = ' '.join(offensive_texts)
        offensive_words = [word for word in jieba.lcut(offensive_corpus) 
                          if len(word) > 1 and word not in stopwords and not word.isdigit()]
        offensive_word_counts = Counter(offensive_words)

        # è®¡ç®—è¯æ±‡çš„æƒ…æ„Ÿå€¾å‘æ€§
        print("  - æ­£åœ¨è®¡ç®—è¯æ±‡æƒ…æ„Ÿå€¾å‘...")
        
        # æ­£é¢è¯ï¼šåœ¨æ­£å¸¸æ–‡æœ¬ä¸­é¢‘ç‡é«˜ï¼Œåœ¨åè§æ–‡æœ¬ä¸­é¢‘ç‡ä½
        positive_words = []
        for word, safe_freq in safe_word_counts.most_common(800):
            offensive_freq = offensive_word_counts.get(word, 0)
            safe_ratio = safe_freq / len(safe_texts) if len(safe_texts) > 0 else 0
            offensive_ratio = offensive_freq / len(offensive_texts) if len(offensive_texts) > 0 else 0
            
            # æ­£é¢è¯æ¡ä»¶ï¼šåœ¨æ­£å¸¸æ–‡æœ¬ä¸­å‡ºç°é¢‘ç‡æ˜æ˜¾é«˜äºåè§æ–‡æœ¬
            if safe_ratio > offensive_ratio * 1.8 and safe_freq >= 3:  # é™ä½é˜ˆå€¼
                positive_words.append(word)
                if len(positive_words) >= 60:  # é™åˆ¶æ•°é‡
                    break

        # è´Ÿé¢è¯ï¼šåœ¨åè§æ–‡æœ¬ä¸­é¢‘ç‡é«˜ï¼Œåœ¨æ­£å¸¸æ–‡æœ¬ä¸­é¢‘ç‡ä½
        negative_words = []
        for word, offensive_freq in offensive_word_counts.most_common(800):
            safe_freq = safe_word_counts.get(word, 0)
            safe_ratio = safe_freq / len(safe_texts) if len(safe_texts) > 0 else 0
            offensive_ratio = offensive_freq / len(offensive_texts) if len(offensive_texts) > 0 else 0
            
            # è´Ÿé¢è¯æ¡ä»¶ï¼šåœ¨åè§æ–‡æœ¬ä¸­å‡ºç°é¢‘ç‡æ˜æ˜¾é«˜äºæ­£å¸¸æ–‡æœ¬
            if offensive_ratio > safe_ratio * 1.8 and offensive_freq >= 3:  # é™ä½é˜ˆå€¼
                negative_words.append(word)
                if len(negative_words) >= 60:  # é™åˆ¶æ•°é‡
                    break

        # æç«¯è¯ï¼šè¡¨ç¤ºç»å¯¹åŒ–ã€æç«¯åŒ–çš„è¯æ±‡
        extreme_patterns = ['éƒ½', 'å…¨éƒ¨', 'æ‰€æœ‰', 'ä¸€å¾‹', 'ç»Ÿç»Ÿ', 'æ€»æ˜¯', 'æ°¸è¿œ', 'ä»æ¥', 'ç»å¯¹', 'è‚¯å®š', 'å¿…ç„¶', 'å¤©ç”Ÿ', 'ç”Ÿæ¥', 'å°±æ˜¯']
        extreme_words = []
        
        all_words = list(safe_word_counts.keys()) + list(offensive_word_counts.keys())
        for word in set(all_words):
            if any(pattern in word for pattern in extreme_patterns) or word in extreme_patterns:
                total_freq = safe_word_counts.get(word, 0) + offensive_word_counts.get(word, 0)
                if total_freq >= 2:  # é™ä½é˜ˆå€¼ï¼šè‡³å°‘å‡ºç°2æ¬¡
                    extreme_words.append(word)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        extreme_words = list(set(extreme_words))[:30]

        # æ„å»ºæƒ…æ„Ÿè¯å…¸
        sentiment_dict = {
            'positive_words': positive_words,
            'negative_words': negative_words,
            'extreme_words': extreme_words
        }

        # ä¿å­˜ä¸ºJSON
        with open(OUTPUT_SENTIMENT_WORDS, 'w', encoding='utf-8') as f:
            json.dump(sentiment_dict, f, ensure_ascii=False, indent=4)

        print(f"âœ… æƒ…æ„Ÿè¯å…¸å·²ä¿å­˜åˆ°: {OUTPUT_SENTIMENT_WORDS}")
        print(f"  - æ­£é¢è¯æ±‡: {len(positive_words)}ä¸ª")
        print(f"  - è´Ÿé¢è¯æ±‡: {len(negative_words)}ä¸ª") 
        print(f"  - æç«¯è¯æ±‡: {len(extreme_words)}ä¸ª")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        print(f"  - æ­£é¢è¯ç¤ºä¾‹: {', '.join(positive_words[:8])}")
        print(f"  - è´Ÿé¢è¯ç¤ºä¾‹: {', '.join(negative_words[:8])}")
        print(f"  - æç«¯è¯ç¤ºä¾‹: {', '.join(extreme_words[:8])}")

    except Exception as e:
        print(f"âŒ æå–æƒ…æ„Ÿè¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°ï¼šä½¿ç”¨ä¸€åŠCOLDatasetè®­ç»ƒå¢å¼ºç‰ˆä¼ ç»Ÿåè§æ£€æµ‹å™¨"""
    print("ğŸš€ åŸºäºä¸€åŠCOLDatasetçš„ä¼ ç»Ÿåè§æ£€æµ‹å™¨å¢å¼ºå·¥å…·")
    print("=" * 70)
    
    # åŠ è½½ä¸€åŠæ•°æ®
    df = load_and_sample_data()
    if df is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  - æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"  - æ­£å¸¸æ ·æœ¬: {sum(df['label'] == 0)} ({sum(df['label'] == 0)/len(df)*100:.1f}%)")
    print(f"  - åè§æ ·æœ¬: {sum(df['label'] == 1)} ({sum(df['label'] == 1)/len(df)*100:.1f}%)")
    
    if 'topic' in df.columns:
        print(f"  - ä¸»é¢˜åˆ†å¸ƒ:")
        topic_counts = df[df['label'] == 1]['topic'].value_counts()
        for topic, count in topic_counts.items():
            print(f"    - {topic}: {count}æ ·æœ¬")
    
    # 1. è®­ç»ƒSVMæ¨¡å‹
    train_and_save_svm_half(df)
    
    # 2. æå–æ•æ„Ÿè¯è¯å…¸
    extract_and_save_sensitive_words_half(df)
    
    # 3. æå–æƒ…æ„Ÿè¯è¯å…¸
    extract_and_save_sentiment_words_half(df)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ ä¸€åŠæ•°æ®å¢å¼ºç‰ˆä¼ ç»Ÿåè§æ£€æµ‹å™¨è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("ğŸ“‹ ç”Ÿæˆæ–‡ä»¶:")
    print(f"  - SVMæ¨¡å‹: {OUTPUT_SVM_MODEL}")
    print(f"  - æ•æ„Ÿè¯è¯å…¸: {OUTPUT_SENSITIVE_WORDS}")
    print(f"  - æƒ…æ„Ÿè¯è¯å…¸: {OUTPUT_SENTIMENT_WORDS}")
    
    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
    if os.path.exists(OUTPUT_SVM_MODEL):
        model_size = os.path.getsize(OUTPUT_SVM_MODEL) / (1024 * 1024)
        print(f"  - æ¨¡å‹å¤§å°: {model_size:.1f} MB")

if __name__ == '__main__':
    main() 