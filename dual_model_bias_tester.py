#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒæ¨¡å‹åè§æ£€æµ‹ä¸çº æ­£äº¤äº’æµ‹è¯•å·¥å…·
åˆ†åˆ«è°ƒç”¨ä¼ ç»Ÿæ¨¡å‹å’ŒBERTæ¨¡å‹è¿›è¡Œåè§æ£€æµ‹ï¼Œå¹¶æä¾›çº æ­£å»ºè®®
"""

import os
import logging
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from traditional_bias_detector import TraditionalBiasDetector
from enhanced_bias_correction_system import SemanticBiasCorrector, CorrectionResult
from dataclasses import dataclass
from typing import Optional, List, Dict
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING)  # åªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯
logger = logging.getLogger(__name__)

@dataclass
class BiasDetectionResult:
    """åè§æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    model_name: str
    has_bias: bool
    confidence: float
    bias_types: List[str]
    details: Dict
    explanation: str

class BertBiasDetector:
    """BERTåè§æ£€æµ‹å™¨"""
    
    def __init__(self, model_path='./coldataset_bias_bert_model'):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½BERTæ¨¡å‹"""
        try:
            if not os.path.exists(self.model_path):
                print(f"âš ï¸ BERTæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
                return False
            
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)
            self.model.to(self.device)
            self.model.eval()
            print("âœ… BERTåè§æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def detect_bias(self, text: str) -> BiasDetectionResult:
        """æ£€æµ‹æ–‡æœ¬åè§"""
        if not self.model or not self.tokenizer:
            return BiasDetectionResult(
                model_name="BERT",
                has_bias=False,
                confidence=0.0,
                bias_types=[],
                details={},
                explanation="æ¨¡å‹æœªåŠ è½½"
            )
        
        try:
            # ç¼–ç æ–‡æœ¬
            inputs = self.tokenizer(
                text,
                return_tensors='pt',
                truncation=True,
                padding=True,
                max_length=512
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probabilities = torch.nn.functional.softmax(logits, dim=-1)
                
                predicted_class = torch.argmax(logits, dim=-1).item()
                confidence = torch.max(probabilities).item()
                
                # åˆ†æç»“æœ
                has_bias = predicted_class == 1  # 1è¡¨ç¤ºoffensive/biased
                
                # ç®€åŒ–çš„åè§ç±»å‹åˆ¤æ–­ï¼ˆåŸºäºå…³é”®è¯ï¼‰
                bias_types = []
                if has_bias:
                    # åŸºäºå…³é”®è¯ç®€å•åˆ¤æ–­åè§ç±»å‹
                    if any(word in text for word in ['ç”·æ€§', 'å¥³æ€§', 'ç”·äºº', 'å¥³äºº', 'ç”·çš„', 'å¥³çš„']):
                        bias_types.append('gender')
                    if any(word in text for word in ['é»‘äºº', 'ç™½äºº', 'äºšæ´²äºº', 'ä¸­å›½äºº', 'æ—¥æœ¬äºº', 'éŸ©å›½äºº']):
                        bias_types.append('race')
                    if any(word in text for word in ['æ²³å—äºº', 'ä¸œåŒ—äºº', 'ä¸Šæµ·äºº', 'åŒ—äº¬äºº', 'å†œæ‘äºº', 'åŸé‡Œäºº']):
                        bias_types.append('region')
                    if not bias_types:
                        bias_types.append('general')
                
                explanation = f"BERTæ¨¡å‹é¢„æµ‹: {'æœ‰åè§' if has_bias else 'æ— åè§'} (ç½®ä¿¡åº¦: {confidence:.3f})"
                
                return BiasDetectionResult(
                    model_name="BERT",
                    has_bias=has_bias,
                    confidence=confidence,
                    bias_types=bias_types,
                    details={
                        'predicted_class': predicted_class,
                        'raw_probabilities': probabilities.cpu().numpy().tolist(),
                        'device': str(self.device)
                    },
                    explanation=explanation
                )
                
        except Exception as e:
            return BiasDetectionResult(
                model_name="BERT",
                has_bias=False,
                confidence=0.0,
                bias_types=[],
                details={'error': str(e)},
                explanation=f"BERTæ£€æµ‹å‡ºé”™: {e}"
            )

class TraditionalBiasDetectorWrapper:
    """ä¼ ç»Ÿåè§æ£€æµ‹å™¨åŒ…è£…ç±»"""
    
    def __init__(self):
        self.detector = TraditionalBiasDetector()
        print("âœ… ä¼ ç»Ÿåè§æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    def detect_bias(self, text: str) -> BiasDetectionResult:
        """æ£€æµ‹æ–‡æœ¬åè§"""
        try:
            # è°ƒç”¨ä¼ ç»Ÿæ£€æµ‹å™¨ - é™ä½é˜ˆå€¼å¢åŠ æ•æ„Ÿæ€§
            result = self.detector.detect_bias(text, threshold_svm=0.25, threshold_sentiment=0.15)
            
            if not result:
                return BiasDetectionResult(
                    model_name="Traditional",
                    has_bias=False,
                    confidence=0.5,
                    bias_types=[],
                    details={},
                    explanation="ä¼ ç»Ÿæ¨¡å‹æ£€æµ‹å¤±è´¥"
                )
            
            summary = result.get('summary', {})
            detection_results = result.get('detection_results', {})
            
            has_bias = summary.get('is_biased', False)
            confidence = summary.get('confidence', 0.0)
            bias_types = summary.get('bias_types', [])
            
            # è·å–è¯¦ç»†ä¿¡æ¯
            sensitive_words = detection_results.get('sensitive_words', {})
            svm_prediction = detection_results.get('svm_prediction', {})
            sentiment_analysis = detection_results.get('sentiment_analysis', {})
            fairness_check = detection_results.get('fairness_check', {})
            
            explanation = f"ä¼ ç»Ÿæ¨¡å‹æ£€æµ‹: {'æœ‰åè§' if has_bias else 'æ— åè§'} (ç½®ä¿¡åº¦: {confidence:.3f})"
            if has_bias and bias_types:
                types_str = 'ã€'.join(bias_types)
                explanation += f"ï¼Œåè§ç±»å‹: {types_str}"
            
            return BiasDetectionResult(
                model_name="Traditional",
                has_bias=has_bias,
                confidence=confidence,
                bias_types=bias_types,
                details={
                    'sensitive_words_found': len(sensitive_words.get('found_words', [])),
                    'svm_probability': svm_prediction.get('probability', 0),
                    'sentiment_intensity': sentiment_analysis.get('intensity', 0),
                    'fairness_violations': len(fairness_check.get('violations', [])),
                    'detection_components': detection_results.get('flow', [])
                },
                explanation=explanation
            )
            
        except Exception as e:
            return BiasDetectionResult(
                model_name="Traditional",
                has_bias=False,
                confidence=0.0,
                bias_types=[],
                details={'error': str(e)},
                explanation=f"ä¼ ç»Ÿæ¨¡å‹æ£€æµ‹å‡ºé”™: {e}"
            )

class DualModelBiasTester:
    """åŒæ¨¡å‹åè§æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ"""
    
    def __init__(self):
        print("ğŸš€ åˆå§‹åŒ–åŒæ¨¡å‹åè§æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ")
        print("=" * 60)
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.traditional_detector = TraditionalBiasDetectorWrapper()
        self.bert_detector = BertBiasDetector()
        
        # åˆå§‹åŒ–çº æ­£å™¨
        self.corrector = SemanticBiasCorrector()
        
        print("=" * 60)
        print("âœ… åŒæ¨¡å‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print()
    
    def detect_with_both_models(self, text: str) -> tuple[BiasDetectionResult, BiasDetectionResult]:
        """ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹åˆ†åˆ«æ£€æµ‹åè§"""
        print(f"ğŸ” æ­£åœ¨æ£€æµ‹æ–‡æœ¬: {text}")
        print("-" * 40)
        
        # åˆ†åˆ«è°ƒç”¨ä¸¤ä¸ªæ£€æµ‹å™¨
        traditional_result = self.traditional_detector.detect_bias(text)
        bert_result = self.bert_detector.detect_bias(text)
        
        return traditional_result, bert_result
    
    def correct_bias(self, text: str, bias_types: List[str]) -> Optional[CorrectionResult]:
        """çº æ­£åè§"""
        if not bias_types:
            return None
        
        try:
            return self.corrector.correct_with_semantic_preservation(text, bias_types)
        except Exception as e:
            print(f"âš ï¸ åè§çº æ­£å¤±è´¥: {e}")
            return None
    
    def display_results(self, traditional_result: BiasDetectionResult, bert_result: BiasDetectionResult):
        """æ˜¾ç¤ºæ£€æµ‹ç»“æœ"""
        print("ğŸ“Š æ£€æµ‹ç»“æœå¯¹æ¯”:")
        print()
        
        # ä¼ ç»Ÿæ¨¡å‹ç»“æœ
        print("ğŸ”§ ä¼ ç»Ÿæ¨¡å‹ (COLDatasetè®­ç»ƒ)")
        print(f"   ç»“æœ: {traditional_result.explanation}")
        if traditional_result.has_bias:
            print(f"   åè§ç±»å‹: {', '.join(traditional_result.bias_types) if traditional_result.bias_types else 'æœªçŸ¥'}")
            print(f"   è¯¦ç»†ä¿¡æ¯: æ•æ„Ÿè¯{traditional_result.details.get('sensitive_words_found', 0)}ä¸ª, "
                  f"SVMæ¦‚ç‡{traditional_result.details.get('svm_probability', 0):.3f}")
        print()
        
        # BERTæ¨¡å‹ç»“æœ
        print("ğŸ§  BERTæ¨¡å‹ (æ·±åº¦å­¦ä¹ )")
        print(f"   ç»“æœ: {bert_result.explanation}")
        if bert_result.has_bias:
            print(f"   åè§ç±»å‹: {', '.join(bert_result.bias_types) if bert_result.bias_types else 'æœªçŸ¥'}")
            print(f"   è®¾å¤‡: {bert_result.details.get('device', 'CPU')}")
        print()
        
        # ç»¼åˆåˆ¤æ–­
        both_detect_bias = traditional_result.has_bias and bert_result.has_bias
        any_detect_bias = traditional_result.has_bias or bert_result.has_bias
        
        if both_detect_bias:
            print("âš ï¸ ç»¼åˆåˆ¤æ–­: ä¸¤ä¸ªæ¨¡å‹éƒ½æ£€æµ‹åˆ°åè§ï¼Œå»ºè®®è¿›è¡Œçº æ­£")
            combined_bias_types = list(set(traditional_result.bias_types + bert_result.bias_types))
            return True, combined_bias_types
        elif any_detect_bias:
            print("âš¡ ç»¼åˆåˆ¤æ–­: ä¸€ä¸ªæ¨¡å‹æ£€æµ‹åˆ°åè§ï¼Œå­˜åœ¨æ½œåœ¨é£é™©")
            combined_bias_types = list(set(traditional_result.bias_types + bert_result.bias_types))
            return True, combined_bias_types
        else:
            print("âœ… ç»¼åˆåˆ¤æ–­: ä¸¤ä¸ªæ¨¡å‹éƒ½æœªæ£€æµ‹åˆ°æ˜æ˜¾åè§")
            return False, []
    
    def interactive_test(self):
        """äº¤äº’å¼æµ‹è¯•"""
        print("ğŸ§ª åŒæ¨¡å‹åè§æ£€æµ‹ä¸çº æ­£äº¤äº’å·¥å…·")
        print("=" * 60)
        print("ğŸ’¡ åŠŸèƒ½è¯´æ˜:")
        print("   - åŒæ—¶ä½¿ç”¨ä¼ ç»Ÿæ¨¡å‹å’ŒBERTæ¨¡å‹æ£€æµ‹åè§")
        print("   - å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„æ£€æµ‹ç»“æœ")
        print("   - æä¾›æ™ºèƒ½åè§çº æ­£å»ºè®®")
        print("   - è¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
        print("=" * 60)
        
        while True:
            try:
                print("\n" + "ğŸ”¹" * 50)
                text = input("è¯·è¾“å…¥è¦æ£€æµ‹çš„æ–‡æœ¬: ").strip()
                
                if not text:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆæ–‡æœ¬")
                    continue
                
                if text.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨åŒæ¨¡å‹åè§æ£€æµ‹ç³»ç»Ÿï¼Œå†è§ï¼")
                    break
                
                print()
                
                # åŒæ¨¡å‹æ£€æµ‹
                traditional_result, bert_result = self.detect_with_both_models(text)
                
                # æ˜¾ç¤ºç»“æœ
                needs_correction, combined_bias_types = self.display_results(traditional_result, bert_result)
                
                # å¦‚æœéœ€è¦çº æ­£
                if needs_correction and combined_bias_types:
                    print("ğŸ”§ æ­£åœ¨ç”Ÿæˆçº æ­£å»ºè®®...")
                    correction_result = self.correct_bias(text, combined_bias_types)
                    
                    if correction_result:
                        print("âœ¨ åè§çº æ­£å»ºè®®:")
                        print(f"   åŸæ–‡: {correction_result.original_text}")
                        print(f"   çº æ­£å: {correction_result.corrected_text}")
                        print(f"   çº æ­£æ–¹æ³•: {correction_result.correction_method}")
                        print(f"   ç½®ä¿¡åº¦: {correction_result.confidence:.3f}")
                        print(f"   ä¿æŒåŸæ„: {'âœ…' if correction_result.preserved_meaning else 'âŒ'}")
                        print(f"   è¯´æ˜: {correction_result.explanation}")
                    else:
                        print("âš ï¸ æ— æ³•ç”Ÿæˆåˆé€‚çš„çº æ­£å»ºè®®ï¼Œå»ºè®®äººå·¥å®¡æŸ¥")
                
                print("\n" + "âœ…" * 50)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
                break
            except Exception as e:
                print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    try:
        tester = DualModelBiasTester()
        tester.interactive_test()
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 